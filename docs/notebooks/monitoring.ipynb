{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Q-jcLd3pnOhU",
   "metadata": {
    "id": "Q-jcLd3pnOhU"
   },
   "source": [
    "<img src=https://raw.githubusercontent.com/superwise-ai/elemeta/cedb93e339a61b6920231cb27f463c7dc6cb9da4/docs/images/superwise_slemeta_white_b.png alt=\"Elemta + Superwise\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Uq965MIbOAkW",
   "metadata": {
    "id": "Uq965MIbOAkW"
   },
   "source": [
    "This notebook provides a quickstart experience for extracting and enriching meta-features from plain text using Elemeta open source package. You will also be guided through Elemeta's two main use cases: \n",
    "* Engineer new features with extracted meta-features to build improved models.\n",
    "* Using Elemeta to monitor NLP use cases (here using Superwise).\n",
    "\n",
    "The notebook includes:\n",
    "* [Installation](#installation)\n",
    "* [Monitor NLP with Superwise and Elemeta](#monitor)\n",
    "    * [Simulation preperation](#simulation_preperation)\n",
    "    * [Create a project](#create_project)\n",
    "    * [Training pipeline](#training_pipeline)\n",
    "    * [Inference pipeline](#inference_pipeline)\n",
    "    * [Ground truth pipeline](#ground_truth_pipeline)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CRugCk3WO9WP",
   "metadata": {
    "id": "CRugCk3WO9WP"
   },
   "source": [
    "# <a name=\"installation\"></a>Installation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YLbwwfzcPoYq",
   "metadata": {
    "id": "YLbwwfzcPoYq"
   },
   "source": [
    "## Install packages\n",
    "Install PyDrive to access Google Drive data directly, Superwise for the Superwise SDK, and Elemeta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "luOElbEUPEex",
   "metadata": {
    "id": "luOElbEUPEex",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install elemeta\n",
    "!pip install superwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SuQM2BR1Pkzl",
   "metadata": {
    "id": "SuQM2BR1Pkzl"
   },
   "source": [
    "## Restart the kernel\n",
    "\n",
    "After installing everything, restart the notebook kernel so it can find the packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Fvp5XGs8Pkzw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fvp5XGs8Pkzw",
    "outputId": "41cef4df-3153-4b8e-99f8-9b4622ccd4bb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Automatically restart kernel after installs\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YiqfzLv-P9RK",
   "metadata": {
    "id": "YiqfzLv-P9RK"
   },
   "source": [
    "## Imports\n",
    "Import the relevant packages into the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1Tlr988SyMeV",
   "metadata": {
    "id": "1Tlr988SyMeV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from elemeta.nlp.runners.metafeature_extractors_runner import MetafeatureExtractorsRunner\n",
    "from elemeta.dataset.dataset import get_tweets_likes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from superwise import Superwise\n",
    "from superwise.models.project import Project\n",
    "from superwise.models.model import Model\n",
    "from superwise.models.version import Version\n",
    "from superwise.models.dataset import Dataset\n",
    "from superwise.resources.superwise_enums import NotifyUpon, ScheduleCron\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T1SM9HMAQKw8",
   "metadata": {
    "id": "T1SM9HMAQKw8"
   },
   "source": [
    "## Read data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17mCRPbOSKHw",
   "metadata": {
    "id": "17mCRPbOSKHw"
   },
   "source": [
    "Read Twitter tweets dataset. We will use only 3 fields: the tweet itself, it's timestamp, and the number of likes (this will be used later on as the label for our prediction task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5yRDTZRTFd",
   "metadata": {
    "id": "1f5yRDTZRTFd"
   },
   "outputs": [],
   "source": [
    "df_full = get_tweets_likes()\n",
    "df_origin = df_full[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e86ed4",
   "metadata": {
    "id": "70e86ed4"
   },
   "source": [
    "# <a name=\"monitor\"></a>Monitor NLP with Superwise and Elemeta\n",
    "This is a quickstart example of how Elemeta can be used to monitor NLP use cases with Superwise Model Observability. Please ensure that you have an active Superwise account, and if you don't have one, [please create one](https://portal.superwise.ai/account/sign-up).\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tBqdJxcarETD",
   "metadata": {
    "id": "tBqdJxcarETD"
   },
   "source": [
    "## <a name=\"simulation_preperation\"></a>Simulation preperation\n",
    "We will split the original Twitter data into three parts to simulate training, inference, and ground truth data pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VPJR5qapq3hU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VPJR5qapq3hU",
    "outputId": "950aef40-9984-4edc-f0b3-0237ec7ee2e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35203, 4)\n",
      "(17339, 4)\n",
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "if \"id\" not in df_full.columns:\n",
    "  df_full = df_full.reset_index().rename({\"index\":\"id\"},axis=1)\n",
    "X_train, X_inference, y_train, y_inference = train_test_split(df_full, df_full.loc[:,'number_of_likes'], test_size=0.33, random_state=42)\n",
    "\n",
    "sample_size = 200\n",
    "train_sampled = X_train[:sample_size]\n",
    "inference_sampled = X_inference[:sample_size]\n",
    "ground_truth_sampled = pd.DataFrame(y_inference[:sample_size]).assign(id=inference_sampled[\"id\"])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_inference.shape)\n",
    "print(ground_truth_sampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tzAtnO8Xq6kW",
   "metadata": {
    "id": "tzAtnO8Xq6kW"
   },
   "source": [
    "## <a name=\"create_project\"></a>Create a project\n",
    "We will programatically create a project and model using the Superwise SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w0bqQbNfmeV8",
   "metadata": {
    "id": "w0bqQbNfmeV8"
   },
   "source": [
    "### Generate tokens\n",
    "Please enter your API token or user token here. See how to generate them or import them [here](https://docs.superwise.ai/docs/authentication)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BxuosHRLrGIg",
   "metadata": {
    "id": "BxuosHRLrGIg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SUPERWISE_CLIENT_ID'] = '[CLIENT_ID]'\n",
    "os.environ['SUPERWISE_SECRET'] = '[SECRET]'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OqSVw1RumnzI",
   "metadata": {
    "id": "OqSVw1RumnzI"
   },
   "source": [
    "### Create a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dGEQ8g0MXsOH",
   "metadata": {
    "id": "dGEQ8g0MXsOH"
   },
   "outputs": [],
   "source": [
    "sw = Superwise()\n",
    "project = Project(\n",
    "    name=\"My NLP Project\",\n",
    "    description=\"Natural Language Processing\"\n",
    ")\n",
    "\n",
    "project = sw.project.create(project)\n",
    "print(f\"New project Created - {project.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0P_8hnQGnc4A",
   "metadata": {
    "id": "0P_8hnQGnc4A"
   },
   "source": [
    "### Create a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aKDqRHhXgdb",
   "metadata": {
    "id": "8aKDqRHhXgdb"
   },
   "outputs": [],
   "source": [
    "nlp_model = Model(\n",
    "    project_id=project.id,\n",
    "    name=\"Tweeter Likes NLP Model\",\n",
    "    description=\"Regression model with simulated data\"\n",
    ")\n",
    "\n",
    "nlp_model = sw.model.create(nlp_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q9upcSSGqvzl",
   "metadata": {
    "id": "q9upcSSGqvzl"
   },
   "source": [
    "## <a name=\"training_pipeline\"></a>Training pipeline\n",
    "In order to predict the number of likes per tweet, we will train a regression model and log the training data into Superwise after Elemeta enrichment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UedJum2Ln1Kt",
   "metadata": {
    "id": "UedJum2Ln1Kt"
   },
   "source": [
    "### Train a new model\n",
    "Based on the training dataset, build a simple classifier model pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z4NrUW7WLku9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "z4NrUW7WLku9",
    "outputId": "97748683-6425-4f07-ea8f-008e67126ffe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;sgdr&#x27;, SGDRegressor(max_iter=3000))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;sgdr&#x27;, SGDRegressor(max_iter=3000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor(max_iter=3000)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('sgdr', SGDRegressor(max_iter=3000))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,SGDRegressor\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('sgdr',SGDRegressor(max_iter=3000))\n",
    "    ])\n",
    "pipe.fit(X_train[\"content\"],y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8JMRSPRrkAKv",
   "metadata": {
    "id": "8JMRSPRrkAKv"
   },
   "source": [
    "### Log training data\n",
    "Prepare the training dataset formated for Superwise, extend it with Elemeta, and send it to Superwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SVFmCRJtrvqx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "SVFmCRJtrvqx",
    "outputId": "2611cae6-7278-401e-883e-9c56f179bcf8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-7e83184e-36b7-4f95-820a-3d6d51953180\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>date_time</th>\n",
       "      <th>number_of_likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10299</th>\n",
       "      <td>10299</td>\n",
       "      <td>I sincerely enjoy this and every moment I get ...</td>\n",
       "      <td>12/11/2014 12:43</td>\n",
       "      <td>4828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49940</th>\n",
       "      <td>49940</td>\n",
       "      <td>Like. Love. Affection. Romance. A double tap. ...</td>\n",
       "      <td>14/02/2016 20:41</td>\n",
       "      <td>1545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45822</th>\n",
       "      <td>45822</td>\n",
       "      <td>With the opening of these 2 centers, @Movimien...</td>\n",
       "      <td>03/07/2015 16:02</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52156</th>\n",
       "      <td>52156</td>\n",
       "      <td>@WValderrama I know this won't mean anything t...</td>\n",
       "      <td>23/05/2015 15:33</td>\n",
       "      <td>12645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44558</th>\n",
       "      <td>44558</td>\n",
       "      <td>ありがとうございます Summersonic Tokyo!! だいすき！</td>\n",
       "      <td>15/08/2015 09:55</td>\n",
       "      <td>32410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12272</th>\n",
       "      <td>12272</td>\n",
       "      <td>@__glitterDICK Happy #cake day to my glitter d...</td>\n",
       "      <td>28/12/2012 18:31</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17036</th>\n",
       "      <td>17036</td>\n",
       "      <td>A night of magical moments, rocknroll and too ...</td>\n",
       "      <td>05/05/2015 17:30</td>\n",
       "      <td>5858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>764</td>\n",
       "      <td>When you could go anywhere for your bday dinne...</td>\n",
       "      <td>27/10/2015 19:37</td>\n",
       "      <td>9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48415</th>\n",
       "      <td>48415</td>\n",
       "      <td>Mmm...pasta. 🍝 Worldwide InstaMeet is coming s...</td>\n",
       "      <td>10/09/2016 15:00</td>\n",
       "      <td>916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41452</th>\n",
       "      <td>41452</td>\n",
       "      <td>Thank you, Kraft Singles, for sounding like a ...</td>\n",
       "      <td>08/03/2014 00:29</td>\n",
       "      <td>7755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e83184e-36b7-4f95-820a-3d6d51953180')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-7e83184e-36b7-4f95-820a-3d6d51953180 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-7e83184e-36b7-4f95-820a-3d6d51953180');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "          id                                            content  \\\n",
       "10299  10299  I sincerely enjoy this and every moment I get ...   \n",
       "49940  49940  Like. Love. Affection. Romance. A double tap. ...   \n",
       "45822  45822  With the opening of these 2 centers, @Movimien...   \n",
       "52156  52156  @WValderrama I know this won't mean anything t...   \n",
       "44558  44558               ありがとうございます Summersonic Tokyo!! だいすき！   \n",
       "...      ...                                                ...   \n",
       "12272  12272  @__glitterDICK Happy #cake day to my glitter d...   \n",
       "17036  17036  A night of magical moments, rocknroll and too ...   \n",
       "764      764  When you could go anywhere for your bday dinne...   \n",
       "48415  48415  Mmm...pasta. 🍝 Worldwide InstaMeet is coming s...   \n",
       "41452  41452  Thank you, Kraft Singles, for sounding like a ...   \n",
       "\n",
       "              date_time  number_of_likes  \n",
       "10299  12/11/2014 12:43             4828  \n",
       "49940  14/02/2016 20:41             1545  \n",
       "45822  03/07/2015 16:02             1661  \n",
       "52156  23/05/2015 15:33            12645  \n",
       "44558  15/08/2015 09:55            32410  \n",
       "...                 ...              ...  \n",
       "12272  28/12/2012 18:31              224  \n",
       "17036  05/05/2015 17:30             5858  \n",
       "764    27/10/2015 19:37             9421  \n",
       "48415  10/09/2016 15:00              916  \n",
       "41452  08/03/2014 00:29             7755  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eIxJ0c1-sBzk",
   "metadata": {
    "id": "eIxJ0c1-sBzk"
   },
   "source": [
    "##### Preparation for Superwise format and Enrichment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0KJwHlebr-vf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0KJwHlebr-vf",
    "outputId": "6b5caefc-ab15-4ea1-c6ff-1aa0d9fc8397"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original dataset had 5 columns\n",
      "Processing...\n",
      "The transformed dataset has 31 columns\n"
     ]
    }
   ],
   "source": [
    "train_sampled[\"predicted_number_of_likes\"] = pipe.predict(train_sampled[\"content\"]).astype(int)\n",
    "\n",
    "# Enrich the training dataset with Elemeta\n",
    "metafeature_extractors_runner = MetafeatureExtractorsRunner()\n",
    "print(\"The original dataset had {} columns\".format(train_sampled.shape[1]))\n",
    "\n",
    "# The enrichment process\n",
    "print(\"Processing...\")\n",
    "train_sampled = metafeature_extractors_runner.run_on_dataframe(dataframe=train_sampled,text_column='content')\n",
    "print(\"The transformed dataset has {} columns\".format(train_sampled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CDVoX-_cvN0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CDVoX-_cvN0f",
    "outputId": "e3b98e67-a0a5-426f-ef00-1701ef6271c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'content', 'date_time', 'number_of_likes',\n",
       "       'predicted_number_of_likes', 'detect_langauge', 'emoji_count',\n",
       "       'text_complexity', 'unique_word_ratio', 'unique_word_count',\n",
       "       'word_regex_matches_count', 'number_count', 'out_of_vocabulary_count',\n",
       "       'must_appear_words_ratio', 'sentence_count', 'sentence_avg_length',\n",
       "       'word_count', 'avg_word_length', 'text_length', 'stop_words_count',\n",
       "       'punctuation_count', 'special_chars_count', 'capital_letters_ratio',\n",
       "       'regex_match_count', 'email_count', 'link_count', 'hashtag_count',\n",
       "       'mention_count', 'syllable_count', 'acronym_count', 'date_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PAn49zDTTLn2",
   "metadata": {
    "id": "PAn49zDTTLn2"
   },
   "outputs": [],
   "source": [
    "from superwise.models.dataset import Dataset\n",
    "from superwise.resources.superwise_enums import DataEntityRole,FeatureType\n",
    "\n",
    "\n",
    "dataset = Dataset.generate_dataset_from_dataframe(name=\"Tweeter Likes Dataset\",\n",
    "                  project_id=project.id,\n",
    "                  dataframe=train_sampled,\n",
    "                  roles={\n",
    "                    DataEntityRole.METADATA.value:[\"content\"],\n",
    "                    DataEntityRole.PREDICTION_VALUE.value:[\"predicted_number_of_likes\"],\n",
    "                    DataEntityRole.TIMESTAMP.value:\"date_time\",\n",
    "                    DataEntityRole.LABEL.value:[\"number_of_likes\"],\n",
    "                    DataEntityRole.ID.value:\"id\"},\n",
    "                    )\n",
    "\n",
    "# Create the dataset in Superwise, may take some time to process\n",
    "dataset = sw.dataset.create(dataset)\n",
    "\n",
    "new_version = Version(\n",
    "    model_id=nlp_model.id,\n",
    "    name=\"1.0.0\",\n",
    "    dataset_id=dataset.id\n",
    ")\n",
    "\n",
    "new_version = sw.version.create(new_version)\n",
    "sw.version.activate(new_version.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5q-6BpXNqv4D",
   "metadata": {
    "id": "5q-6BpXNqv4D"
   },
   "source": [
    "## <a name=\"inference_pipeline\"></a>Inference pipeline\n",
    "Produce model inference predictions and log them to Superwise for monitoring. Inference logs will be sent in batches once Elemeta has enriched them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T-Uf6oNArvwU",
   "metadata": {
    "id": "T-Uf6oNArvwU"
   },
   "outputs": [],
   "source": [
    "inference_sampled.loc[:,\"predicted_number_of_likes\"] = pipe.predict(inference_sampled[\"content\"]).astype(int)\n",
    "\n",
    "# prep for Superwise format\n",
    "prediction_time_vector = pd.Timestamp.now().floor('h') - \\\n",
    "    pd.TimedeltaIndex(inference_sampled.reset_index(drop=True).index // int(inference_sampled.shape[0] // 30), unit='D')\n",
    "\n",
    "ongoing_predictions = inference_sampled.assign(\n",
    "    date_time=prediction_time_vector,\n",
    ")\n",
    "\n",
    "#util function \n",
    "def chunks(df, n):\n",
    "    \"\"\"Yield successive n-sized chunks from df.\"\"\"\n",
    "    for i in range(0, df.shape[0], n):\n",
    "        yield df[i:i + n]\n",
    "\n",
    "# break the inference data into chunks\n",
    "ongoing_predictions_chunks = chunks(ongoing_predictions, 50) # batches of 50\n",
    "\n",
    "transaction_ids = list()\n",
    "# for each chunk\n",
    "for ongoing_predictions_chunk in ongoing_predictions_chunks:\n",
    "    \n",
    "    # enrich with Elemeta\n",
    "    ongoing_predictions_chunk = metafeature_extractors_runner.run_on_dataframe(dataframe=ongoing_predictions_chunk,text_column=\"content\")\n",
    "    \n",
    "    # send to Superwise\n",
    "    transaction_id = sw.transaction.log_records(\n",
    "        model_id=nlp_model.id, \n",
    "        version_id=new_version.id, \n",
    "        records=ongoing_predictions_chunk.to_dict(orient=\"records\")\n",
    "    )\n",
    "    transaction_ids.append(transaction_id)\n",
    "    print(transaction_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vwD9VGPase6Y",
   "metadata": {
    "id": "vwD9VGPase6Y"
   },
   "source": [
    "## <a name=\"ground_truth_pipeline\"></a>Ground truth pipeline\n",
    "Simulate ground truth collection and log it to Superwise for monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hT0eQGnKsj7e",
   "metadata": {
    "id": "hT0eQGnKsj7e"
   },
   "outputs": [],
   "source": [
    "# prep for Superwise format\n",
    "prediction_time_vector = pd.Timestamp.now().floor('h') - \\\n",
    "    pd.TimedeltaIndex(ground_truth_sampled.reset_index(drop=True).index // int(ground_truth_sampled.shape[0] // 30), unit='D')\n",
    "\n",
    "ongoing_labels = ground_truth_sampled.assign(\n",
    "    id = ground_truth_sampled[\"id\"]\n",
    ")\n",
    "\n",
    "# break the label data into chunks\n",
    "ongoing_labels_chunks = chunks(ongoing_labels, 50)\n",
    "\n",
    "transaction_ids = list()\n",
    "# for each chunk\n",
    "for ongoing_labels_chunk in ongoing_labels_chunks:\n",
    "    # send to Superwise\n",
    "    transaction_id = sw.transaction.log_records(\n",
    "        model_id=nlp_model.id, \n",
    "        version_id=new_version.id, \n",
    "        records=ongoing_labels_chunk.to_dict(orient=\"records\")\n",
    "    )\n",
    "    transaction_ids.append(transaction_id)\n",
    "    print(transaction_id)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "l1sY29UmSk4i",
    "te_emnmRSnSr",
    "GQX3C8luS3Y4",
    "A2AJWBZ8ToAT",
    "N2ZJ2fxbXmfY",
    "1Il7aFzOXxCZ",
    "ad9CRXB8YSVY",
    "qOGMYgPTZOId",
    "0WVbjyKFwYEo"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
